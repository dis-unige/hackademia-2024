{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Septante nuances de swisscovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "import re\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paramètres\n",
    "swisscovery_api = 'https://api-eu.hosted.exlibrisgroup.com/primo/v1/search?vid=41SLSP_UGE:VU1&tab=CentralIndex'\n",
    "swisscovery_key = 'xxx' # Sandbox\n",
    "\n",
    "# Recherche pour les tests \n",
    "# recherche = \"Je veux savoir ce qu'est le bosson de Higgs\"\n",
    "\n",
    "flex_subtitle = \"built using jupyter-flex\"\n",
    "flex_external_link = \"https://github.com/dis-unige/hackademia-2024/tests/test_swisscoveryIA.ipynb\"\n",
    "\n",
    "flex_title = \"swisscoveryIA\"\n",
    "flex_show_source = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "size=8"
    ]
   },
   "source": [
    "### Pose ta question en langage naturel pour explorer la collection de la Bibliothèque de l'UNIGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked2(event):\n",
    "    print(\"TEST OK\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(f\"Recherche lancée, veuillez patienter, l'IA est un peu lente... {search.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function de chat\n",
    "def chat(question):\n",
    "    # Load the LlamaCpp language model, adjust GPU usage based on your hardware\n",
    "    llm = LlamaCpp(\n",
    "        model_path=\"C:/Users/pablo/AI/llms/llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "        temperature=0.5,\n",
    "        n_ctx=10000,\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=9900,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "        max_tokens=512,\n",
    "        n_threads=multiprocessing.cpu_count() - 1,\n",
    "        ## repeat_penalty=1.5,\n",
    "        # top_p=0.5,\n",
    "        verbose=False,  # Enable detailed logging for debugging\n",
    "    )\n",
    "    \n",
    "    # Define the prompt template with a placeholder for the question\n",
    "    template = \"\"\"\n",
    "    Question: I want an concise explanation about the question \"{question}\" and also to transform the question into a booleen search strategy that can be used in a library catalog.\n",
    "    The search query can be constructed using several synonyms of the subject in french and english. All the terms of the query can be combined with OR.\n",
    "    Put the string '[explanation]' before your explanation about the question.\n",
    "    Put the string '[query]' before que search query.\n",
    "    Don't add comments inside the query, give only the serach strategy the we can use in our library database.\n",
    "    Please respect this structure on the answer: '[explanation] the subject explanation. [query] the search strategy' and don't add explanations after the query\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    \n",
    "    # Create an LLMChain to manage interactions with the prompt and model\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    \n",
    "    # print(\"Chatbot initialized, ready to chat...\")\n",
    "    while True:\n",
    "        # question = input(\"> \")\n",
    "        # print('start IA : ' + str(datetime.now())) \n",
    "        # answer = llm_chain.run(question)\n",
    "        answer = llm_chain.invoke(question)\n",
    "        # print(answer, '\\n')\n",
    "        # print(\"Answer done\")\n",
    "        # print('end IA : ' + str(datetime.now())) \n",
    "        return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = widgets.Text(placeholder='Recherche swisscovery')\n",
    "button = widgets.Button(description=\"Go!\")\n",
    "output = widgets.Output()\n",
    "\n",
    "display(search, button, output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(f\"Recherche lancée, veuillez patienter, l'IA est un peu lente... \")\n",
    "        recherche = search.value\n",
    "        # print('ta recherche  = ' + myquery)\n",
    "        answer = chat(recherche)\n",
    "\n",
    "        # extraction de la query\n",
    "        query = answer['text']\n",
    "        query = query.replace('`', '')\n",
    "        query = query.replace('´', '')\n",
    "        if (query[0] == '\\''):\n",
    "            query = query[1:]\n",
    "        if (query[-1] == '\\''):\n",
    "            query = query[:-1]\n",
    "        if (query[0] == ' '):\n",
    "            query = query[1:]\n",
    "        if (query[-1] == ' '):\n",
    "            query = query[:-1]\n",
    "        \n",
    "        # remplacement des retours de ligne\n",
    "        query = query.replace('[explanation]', ':::')\n",
    "        query = query.replace('[query]', '|||')\n",
    "        query = query.replace('\\n', '£££')\n",
    "        query = query + '_;_'\n",
    "\n",
    "        if ('|||' in query) and (':::' in query) > 0:\n",
    "            # print (\"Séparateurs OK\")\n",
    "            pattern = r\"^(.*)\\|\\|\\|(.*)_;_\"\n",
    "            match = re.search(pattern, query)\n",
    "            answer_prof = match.group(1)\n",
    "            query_clean = match.group(2)\n",
    "        \n",
    "        else :\n",
    "            print ('ERROR, la réponse est mal formatée ! (c\\'est ça un Hackathon....)')\n",
    "\n",
    "        # nettoyage des deux parties\n",
    "        answer_prof = answer_prof.replace(':::' , '')\n",
    "        answer_prof = answer_prof.replace('£££' , ' ')\n",
    "        answer_prof = answer_prof.replace('  ' , ' ')\n",
    "        answer_prof = answer_prof.replace('  ' , ' ')\n",
    "        answer_prof = answer_prof.replace(':::' , '')\n",
    "        answer_prof = answer_prof.strip()\n",
    "        print('')\n",
    "        print('### Réponse de l\\'IA : ')\n",
    "        print(answer_prof)\n",
    "        print('')\n",
    "        print('')\n",
    "        print ('### Vous devriez vérifier cette réponse en consultant les documents de notre collection : ')\n",
    "        print ('')\n",
    "        print ('')\n",
    "\n",
    "        query_clean = query_clean.replace(':::' , '')\n",
    "        if ('£££' in query_clean) :\n",
    "            query_clean = query_clean[:query_clean.find('£££')]\n",
    "        query_clean = query_clean.strip()\n",
    "        # print(query_clean)\n",
    "\n",
    "        # convertir en URL\n",
    "        query_url = swisscovery_api + '&q=any,contains,' + urllib.parse.quote_plus(query_clean) + '&apikey=' + swisscovery_key\n",
    "        # print(query_url)\n",
    "\n",
    "        # requête sur l'API\n",
    "        r = requests.get(query_url)\n",
    "        # print (r.json())\n",
    "\n",
    "        # nombre de résultats\n",
    "        sw_json = r.json()\n",
    "        sw_total = str(sw_json['info']['total'])\n",
    "        \n",
    "        # Affichage des résultats\n",
    "        mylist = ''\n",
    "        docs = sw_json['docs']\n",
    "        for doc in docs :\n",
    "            mylist = mylist + doc['pnx']['display']['title'][0]\n",
    "            if ('contributor' in doc['pnx']['display']) : \n",
    "                mylist = mylist + '. - '\n",
    "                i = 0\n",
    "                for contributor in doc['pnx']['display']['contributor']:\n",
    "                    if i < 3 :\n",
    "                        mylist = mylist + contributor[:contributor.find('$')] + ' ; '\n",
    "                    i = i + 1\n",
    "            if ('ispartof' in doc['pnx']['display']) : \n",
    "                mylist = mylist  + doc['pnx']['display']['ispartof'][0][:doc['pnx']['display']['ispartof'][0].find('$')] + ', '\n",
    "            if ('date' in doc['pnx']['display']) : \n",
    "                mylist = mylist + doc['pnx']['display']['date'][0] + ', '\n",
    "            if ('mms' in doc['pnx']['display']) : \n",
    "                mylist = mylist + ' URL : https://slsp-unige.primo.exlibrisgroup.com/discovery/search?tab=41SLSP_UGE_MyInst_CI&search_scope=MyInst_and_CI&vid=41SLSP_UGE:VU1&offset=0&query=any,contains,' + doc['pnx']['display']['mms'][0]\n",
    "            mylist = mylist + '\\n\\n'\n",
    "        print (mylist)\n",
    "        print ('')\n",
    "        print ('Lancer la recherche créée par l\\'IA sur swisscovery : https://slsp-unige.primo.exlibrisgroup.com/discovery/search?tab=41SLSP_UGE_MyInst_CI&search_scope=MyInst_and_CI&vid=41SLSP_UGE:VU1&offset=0&query=any,contains,' + urllib.parse.quote_plus(query_clean))\n",
    "        print ('')\n",
    "       \n",
    "button.on_click(on_button_clicked)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
